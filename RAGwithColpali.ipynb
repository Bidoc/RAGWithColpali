{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers pillow PyMuPDF anthropic streamlit pyngrok\n",
        "!pip install colpali-engine==0.1.1\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "ngrok_token = getpass.getpass(\"Enter your ngrok auth token: \")\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "streamlit_app_code = '''\n",
        "import streamlit as st\n",
        "import torch\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "import anthropic\n",
        "import base64\n",
        "import io\n",
        "from transformers import AutoProcessor\n",
        "from colpali_engine.models.paligemma_colbert_architecture import ColPali\n",
        "from colpali_engine.utils.colpali_processing_utils import process_images, process_queries\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Simple custom evaluator optimized for high GPU memory\n",
        "class SimpleEvaluator:\n",
        "    def __init__(self, is_multi_vector=True, device=\"cuda\"):\n",
        "        self.is_multi_vector = is_multi_vector\n",
        "        self.device = device\n",
        "\n",
        "    def evaluate(self, query_embeddings, doc_embeddings):\n",
        "        \"\"\"ColPali multi-vector similarity evaluation - GPU optimized\"\"\"\n",
        "        # All operations on GPU, convert to float32 to avoid BFloat16 issues\n",
        "        query_emb = torch.stack(query_embeddings).float().to(self.device)\n",
        "        doc_emb = torch.stack(doc_embeddings).float().to(self.device)\n",
        "\n",
        "        # ColPali multi-vector retrieval on GPU\n",
        "        with torch.no_grad():\n",
        "            scores = []\n",
        "            for q_idx in range(query_emb.shape[0]):\n",
        "                q = query_emb[q_idx]  # [seq_len, dim]\n",
        "\n",
        "                # Normalize query\n",
        "                q_norm = torch.nn.functional.normalize(q, p=2, dim=-1)\n",
        "\n",
        "                # Batch process all documents at once\n",
        "                d_norm = torch.nn.functional.normalize(doc_emb, p=2, dim=-1)\n",
        "\n",
        "                # Compute similarity: [num_docs, query_seq_len, doc_seq_len]\n",
        "                sim_matrix = torch.matmul(\n",
        "                    q_norm.unsqueeze(0),  # [1, query_seq_len, dim]\n",
        "                    d_norm.transpose(-2, -1)  # [num_docs, dim, doc_seq_len]\n",
        "                )\n",
        "\n",
        "                # Max pooling: [num_docs, query_seq_len]\n",
        "                max_sim_per_query_token = torch.max(sim_matrix, dim=-1)[0]\n",
        "\n",
        "                # Average over query tokens: [num_docs]\n",
        "                doc_scores = torch.mean(max_sim_per_query_token, dim=-1)\n",
        "\n",
        "                # Convert to float32 before numpy conversion\n",
        "                scores.append(doc_scores.float().cpu().numpy())\n",
        "\n",
        "        return np.array(scores)\n",
        "\n",
        "class ColPaliRAGChain:\n",
        "    def __init__(self, anthropic_api_key, use_gpu_storage=True):\n",
        "        self.anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
        "        self.model = None\n",
        "        self.processor = None\n",
        "        self.retriever_evaluator = None\n",
        "        self.document_embeddings = []\n",
        "        self.document_metadata = []\n",
        "        self.is_initialized = False\n",
        "        self.use_gpu_storage = use_gpu_storage\n",
        "        self.device = \"cuda\"\n",
        "\n",
        "    def initialize_colpali(self):\n",
        "        \"\"\"Initialize ColPali model\"\"\"\n",
        "        if self.is_initialized:\n",
        "            return True\n",
        "\n",
        "        with st.spinner(\"Loading ColPali model...\"):\n",
        "            model_name = \"vidore/colpali\"\n",
        "            self.model = ColPali.from_pretrained(\n",
        "                \"vidore/colpaligemma-3b-mix-448-base\",\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=\"cuda\"\n",
        "            ).eval()\n",
        "            self.model.load_adapter(model_name)\n",
        "            self.processor = AutoProcessor.from_pretrained(model_name)\n",
        "            self.retriever_evaluator = SimpleEvaluator(is_multi_vector=True, device=self.device)\n",
        "            self.is_initialized = True\n",
        "        return True\n",
        "\n",
        "    def pdf_to_patches(self, pdf_file, patch_size=(448, 448)):\n",
        "        \"\"\"Convert PDF file to patches\"\"\"\n",
        "        pdf_file.seek(0)\n",
        "        pdf_bytes = pdf_file.read()\n",
        "        doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
        "\n",
        "        all_patches = []\n",
        "        patch_metadata = []\n",
        "\n",
        "        progress_bar = st.progress(0)\n",
        "        total_pages = len(doc)\n",
        "\n",
        "        for page_num in range(total_pages):\n",
        "            page = doc[page_num]\n",
        "\n",
        "            # Convert page to image\n",
        "            mat = fitz.Matrix(2, 2)\n",
        "            pix = page.get_pixmap(matrix=mat)\n",
        "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "\n",
        "            # Create exactly 1024 patches (32x32 grid)\n",
        "            patches = self.create_patches(img, patch_size)\n",
        "\n",
        "            for i, patch in enumerate(patches):\n",
        "                all_patches.append(patch)\n",
        "                patch_metadata.append({\n",
        "                    'page_num': page_num,\n",
        "                    'patch_id': i,\n",
        "                    'original_image': img,\n",
        "                    'grid_row': i // 32,\n",
        "                    'grid_col': i % 32\n",
        "                })\n",
        "\n",
        "            progress_bar.progress((page_num + 1) / total_pages)\n",
        "\n",
        "        doc.close()\n",
        "        return all_patches, patch_metadata\n",
        "\n",
        "    def create_patches(self, image, patch_size=(448, 448), grid_size=32):\n",
        "        \"\"\"Create exactly 1024 patches (32x32 grid) from image\"\"\"\n",
        "        patches = []\n",
        "        width, height = image.size\n",
        "\n",
        "        # Calculate patch dimensions based on image size\n",
        "        patch_width = width // grid_size\n",
        "        patch_height = height // grid_size\n",
        "\n",
        "        for row in range(grid_size):\n",
        "            for col in range(grid_size):\n",
        "                # Calculate patch coordinates\n",
        "                left = col * patch_width\n",
        "                top = row * patch_height\n",
        "                right = min(left + patch_width, width)\n",
        "                bottom = min(top + patch_height, height)\n",
        "\n",
        "                # Extract patch\n",
        "                patch = image.crop((left, top, right, bottom))\n",
        "\n",
        "                # Resize to standard patch size for ColPali\n",
        "                patch_resized = patch.resize(patch_size, Image.Resampling.LANCZOS)\n",
        "                patches.append(patch_resized)\n",
        "\n",
        "        return patches\n",
        "\n",
        "    def embed_documents(self, patches, patch_metadata):\n",
        "        \"\"\"Embed document patches using ColPali\"\"\"\n",
        "        if not self.is_initialized:\n",
        "            self.initialize_colpali()\n",
        "\n",
        "        with st.spinner(\"Creating embeddings...\"):\n",
        "            dataloader = DataLoader(\n",
        "                patches,\n",
        "                batch_size=4,\n",
        "                shuffle=False,\n",
        "                collate_fn=lambda x: process_images(self.processor, x),\n",
        "            )\n",
        "\n",
        "            embeddings = []\n",
        "            progress_bar = st.progress(0)\n",
        "            total_batches = len(dataloader)\n",
        "\n",
        "            for i, batch_doc in enumerate(dataloader):\n",
        "                with torch.no_grad():\n",
        "                    batch_doc = {k: v.to(self.model.device) for k, v in batch_doc.items()}\n",
        "                    embeddings_doc = self.model(**batch_doc)\n",
        "\n",
        "                # Store on GPU\n",
        "                if self.use_gpu_storage:\n",
        "                    embeddings.extend(list(torch.unbind(embeddings_doc)))  # Keep on GPU\n",
        "                else:\n",
        "                    embeddings.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))\n",
        "\n",
        "                progress_bar.progress((i + 1) / total_batches)\n",
        "\n",
        "            self.document_embeddings = embeddings\n",
        "            self.document_metadata = patch_metadata\n",
        "\n",
        "            storage_location = \"GPU\" if self.use_gpu_storage else \"CPU\"\n",
        "            st.success(f\"Created {len(embeddings)} embeddings stored in {storage_location} memory\")\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "    def embed_query(self, query_text):\n",
        "        \"\"\"Embed a single query\"\"\"\n",
        "        if not self.is_initialized:\n",
        "            self.initialize_colpali()\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            [query_text],\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            collate_fn=lambda x: process_queries(\n",
        "                self.processor,\n",
        "                x,\n",
        "                Image.new(\"RGB\", (448, 448), (255, 255, 255))\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        for batch_query in dataloader:\n",
        "            with torch.no_grad():\n",
        "                batch_query = {k: v.to(self.model.device) for k, v in batch_query.items()}\n",
        "                embeddings_query = self.model(**batch_query)\n",
        "            return list(torch.unbind(embeddings_query.to(\"cpu\")))[0]\n",
        "\n",
        "    def retrieve_diverse_pages(self, query_text, top_k_pages=3):\n",
        "        \"\"\"Retrieve top patches ensuring page diversity\"\"\"\n",
        "        query_embedding = self.embed_query(query_text)\n",
        "        scores = self.retriever_evaluator.evaluate([query_embedding], self.document_embeddings)\n",
        "\n",
        "        # Get all patch scores with metadata\n",
        "        all_results = []\n",
        "        for idx, score in enumerate(scores[0]):\n",
        "            all_results.append({\n",
        "                'patch_idx': int(idx),\n",
        "                'score': float(score),\n",
        "                'metadata': self.document_metadata[idx]\n",
        "            })\n",
        "\n",
        "        # Sort by score (best first)\n",
        "        all_results.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "        # Select top patches ensuring page diversity\n",
        "        selected_pages = {}\n",
        "        page_results = []\n",
        "\n",
        "        for result in all_results:\n",
        "            page_num = result['metadata']['page_num']\n",
        "\n",
        "            # Add this page if we haven't seen it yet\n",
        "            if page_num not in selected_pages:\n",
        "                selected_pages[page_num] = result\n",
        "                page_results.append(result)\n",
        "\n",
        "                # Stop when we have enough diverse pages\n",
        "                if len(page_results) >= top_k_pages:\n",
        "                    break\n",
        "            else:\n",
        "                # Update if this patch has a better score for this page\n",
        "                if result['score'] > selected_pages[page_num]['score']:\n",
        "                    selected_pages[page_num] = result\n",
        "                    # Update in page_results too\n",
        "                    for i, page_result in enumerate(page_results):\n",
        "                        if page_result['metadata']['page_num'] == page_num:\n",
        "                            page_results[i] = result\n",
        "                            break\n",
        "\n",
        "        return page_results\n",
        "\n",
        "    def ask_claude_multiple(self, images, query, page_numbers):\n",
        "        \"\"\"Send multiple images + query to Claude\"\"\"\n",
        "        content = []\n",
        "\n",
        "        # Add all images\n",
        "        for i, image in enumerate(images):\n",
        "            buffer = io.BytesIO()\n",
        "            if image.mode != 'RGB':\n",
        "                image = image.convert('RGB')\n",
        "            image.save(buffer, format='PNG')\n",
        "            image_b64 = base64.b64encode(buffer.getvalue()).decode()\n",
        "\n",
        "            content.append({\n",
        "                \"type\": \"image\",\n",
        "                \"source\": {\n",
        "                    \"type\": \"base64\",\n",
        "                    \"media_type\": \"image/png\",\n",
        "                    \"data\": image_b64\n",
        "                }\n",
        "            })\n",
        "\n",
        "        # Add text query\n",
        "        page_list = \", \".join([f\"Page {p}\" for p in page_numbers])\n",
        "        content.append({\n",
        "            \"type\": \"text\",\n",
        "            \"text\": f\"Based on these document images from {page_list}, please answer: {query} also Please review all the provided pages and give a comprehensive answer based on the most relevant information found.\"\n",
        "        })\n",
        "\n",
        "        response = self.anthropic_client.messages.create(\n",
        "            model=\"claude-3-5-sonnet-20241022\",\n",
        "            max_tokens=2000,  # Increased for multiple page context\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": content\n",
        "            }]\n",
        "        )\n",
        "\n",
        "        return response.content[0].text\n",
        "\n",
        "    def rag_query(self, query_text, top_k_pages=3):\n",
        "        \"\"\"Complete RAG pipeline: Retrieve + Generate with diverse pages\"\"\"\n",
        "        # Retrieve top pages ensuring diversity\n",
        "        retrieval_results = self.retrieve_diverse_pages(query_text, top_k_pages)\n",
        "\n",
        "        # Extract images and page numbers (already diverse)\n",
        "        images = [result['metadata']['original_image'] for result in retrieval_results]\n",
        "        page_numbers = [result['metadata']['page_num'] + 1 for result in retrieval_results]\n",
        "        scores = [result['score'] for result in retrieval_results]\n",
        "\n",
        "        # Generate answer with Claude using multiple pages\n",
        "        answer = self.ask_claude_multiple(images, query_text, page_numbers)\n",
        "\n",
        "        return {\n",
        "            'query': query_text,\n",
        "            'answer': answer,\n",
        "            'source_pages': page_numbers,\n",
        "            'confidence_scores': scores,\n",
        "            'num_pages_used': len(images)\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"ColPali + Claude RAG\",\n",
        "        page_icon=\"📄\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"ColPali + Claude RAG System\")\n",
        "    st.markdown(\"Upload a PDF and ask questions about its content!\")\n",
        "\n",
        "    # Sidebar for API key\n",
        "    with st.sidebar:\n",
        "        st.header(\"Configuration\")\n",
        "        api_key = st.text_input(\n",
        "            \"Anthropic API Key\",\n",
        "            type=\"password\",\n",
        "            help=\"Enter your Anthropic API key\"\n",
        "        )\n",
        "\n",
        "        # GPU storage option\n",
        "        use_gpu_storage = st.checkbox(\n",
        "            \"Store embeddings in GPU memory\",\n",
        "            value=True,\n",
        "            help=\"Faster retrieval with high GPU memory\"\n",
        "        )\n",
        "\n",
        "        # Retrieval configuration\n",
        "        st.subheader(\"Retrieval Settings\")\n",
        "        top_k_pages = st.slider(\n",
        "            \"Number of pages to retrieve\",\n",
        "            min_value=1,\n",
        "            max_value=10,\n",
        "            value=3,\n",
        "            help=\"More pages = better accuracy but slower processing\"\n",
        "        )\n",
        "\n",
        "        if not api_key:\n",
        "            st.warning(\"Please enter your Anthropic API key to continue.\")\n",
        "            st.stop()\n",
        "\n",
        "    # Initialize RAG chain\n",
        "    if 'rag_chain' not in st.session_state:\n",
        "        st.session_state.rag_chain = ColPaliRAGChain(api_key, use_gpu_storage)\n",
        "\n",
        "    # Main interface\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"Document Upload\")\n",
        "\n",
        "        uploaded_file = st.file_uploader(\n",
        "            \"Choose a PDF file\",\n",
        "            type=\"pdf\",\n",
        "            help=\"Upload a PDF document to analyze\"\n",
        "        )\n",
        "\n",
        "        if uploaded_file is not None:\n",
        "            if st.button(\"Process Document\", type=\"primary\"):\n",
        "                # Process PDF\n",
        "                patches, metadata = st.session_state.rag_chain.pdf_to_patches(uploaded_file)\n",
        "                st.success(f\"Extracted {len(patches)} patches from {len(set(m['page_num'] for m in metadata))} pages\")\n",
        "\n",
        "                # Embed documents\n",
        "                embeddings = st.session_state.rag_chain.embed_documents(patches, metadata)\n",
        "                st.success(f\"Created {len(embeddings)} embeddings\")\n",
        "                st.session_state.document_processed = True\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"Ask Questions\")\n",
        "\n",
        "        if 'document_processed' not in st.session_state:\n",
        "            st.info(\"Please upload and process a document first\")\n",
        "        else:\n",
        "            query = st.text_input(\n",
        "                \"Enter your question:\",\n",
        "                placeholder=\"What is the main topic of this document?\"\n",
        "            )\n",
        "\n",
        "            if st.button(\"Get Answer\", type=\"primary\") and query:\n",
        "                with st.spinner(\"Searching and generating answer...\"):\n",
        "                    result = st.session_state.rag_chain.rag_query(query, top_k_pages)\n",
        "\n",
        "                # Display results\n",
        "                st.success(\"Answer generated!\")\n",
        "\n",
        "                st.subheader(\"Results\")\n",
        "                st.write(f\"**Question:** {result['query']}\")\n",
        "                st.write(f\"**Answer:** {result['answer']}\")\n",
        "\n",
        "                # Metadata\n",
        "                with st.expander(\"Source Information\"):\n",
        "                    st.write(f\"**Source Pages:** {', '.join(map(str, result['source_pages']))}\")\n",
        "                    st.write(f\"**Pages Used:** {result['num_pages_used']}\")\n",
        "                    st.write(f\"**Confidence Scores:** {[f'{score:.4f}' for score in result['confidence_scores']]}\")\n",
        "\n",
        "                    # Show individual page scores\n",
        "                    for i, (page, score) in enumerate(zip(result['source_pages'], result['confidence_scores'])):\n",
        "                        st.write(f\"  - Page {page}: {score:.4f}\")\n",
        "\n",
        "                # Store in history\n",
        "                if 'query_history' not in st.session_state:\n",
        "                    st.session_state.query_history = []\n",
        "                st.session_state.query_history.append(result)\n",
        "\n",
        "            # Query history\n",
        "            if 'query_history' in st.session_state and st.session_state.query_history:\n",
        "                st.subheader(\"Recent Questions\")\n",
        "                for i, hist_result in enumerate(reversed(st.session_state.query_history[-5:])):\n",
        "                    with st.expander(f\"Q: {hist_result['query'][:50]}...\"):\n",
        "                        st.write(f\"**A:** {hist_result['answer']}\")\n",
        "                        if 'source_pages' in hist_result:  # New multi-page format\n",
        "                            st.write(f\"**Source:** Pages {', '.join(map(str, hist_result['source_pages']))}\")\n",
        "                        else:  # Old single-page format (backwards compatibility)\n",
        "                            st.write(f\"**Source:** Page {hist_result.get('source_page', 'Unknown')}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "with open('/content/colpali_app.py', 'w') as f:\n",
        "    f.write(streamlit_app_code)\n",
        "\n",
        "print(\"Streamlit app created successfully!\")\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    \"\"\"Run Streamlit app\"\"\"\n",
        "    subprocess.run(['streamlit', 'run', '/content/colpali_app.py', '--server.port=8501'])\n",
        "\n",
        "streamlit_thread = threading.Thread(target=run_streamlit)\n",
        "streamlit_thread.daemon = True\n",
        "streamlit_thread.start()\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"\\\\n{'='*50}\")\n",
        "print(f\"Public URL: {public_url}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "while True:\n",
        "    time.sleep(60)"
      ],
      "metadata": {
        "id": "i3xYT7DeVrzY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b131a561-9c6e-483d-ec30-5a2fc0fb04a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.1)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.55.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: colpali-engine==0.1.1 in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.11/dist-packages (from colpali-engine==0.1.1) (1.4.0)\n",
            "Requirement already satisfied: peft<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from colpali-engine==0.1.1) (0.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from colpali-engine==0.1.1) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from colpali-engine==0.1.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from colpali-engine==0.1.1) (4.52.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (1.8.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali-engine==0.1.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2.0->colpali-engine==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->colpali-engine==0.1.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->colpali-engine==0.1.1) (0.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->colpali-engine==0.1.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->colpali-engine==0.1.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->colpali-engine==0.1.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->colpali-engine==0.1.1) (2025.6.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft<0.12.0,>=0.11.0->colpali-engine==0.1.1) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2.0->colpali-engine==0.1.1) (3.0.2)\n",
            "Enter your ngrok auth token: ··········\n",
            "Streamlit app created successfully!\n",
            "\\n==================================================\n",
            "Streamlit app is running!\n",
            "Public URL: NgrokTunnel: \"https://6219-34-67-22-190.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "==================================================\n",
            "\\nCopy the URL above and open it in your browser to access the app.\n",
            "The app will remain active as long as this Colab session is running.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2598596674.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;31m# Keep the session alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}